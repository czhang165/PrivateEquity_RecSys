{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Model Training\n", "Train Two-Tower and Deep Ranking models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import torch\n", "import pytorch_lightning as pl\n", "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "import os\n", "\n", "# Import our custom modules\n", "from models import TwoTowerModel, PairwiseDeepRankingModel, FeatureEncoder\n", "from datasets import (\n", "    InvestorDealDataset, PairwiseRankingDataset, \n", "    collate_fn, pairwise_collate_fn\n", ")\n", "\n", "# Set seeds\n", "np.random.seed(42)\n", "torch.manual_seed(42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["interactions_df = pd.read_csv('data/enhanced_interactions.csv', parse_dates=['timestamp'])\n", "investor_df = pd.read_csv('data/investor_features.csv')\n", "deal_df = pd.read_csv('data/deal_features.csv')\n", "\n", "print(f\"Loaded {len(interactions_df)} interactions\")\n", "print(f\"Loaded {len(investor_df)} investors\")\n", "print(f\"Loaded {len(deal_df)} deals\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prepare Feature Encoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encoder = FeatureEncoder()\n", "encoder.fit(investor_df, deal_df)\n", "\n", "# Create models directory\n", "os.makedirs('models', exist_ok=True)\n", "os.makedirs('models/checkpoints', exist_ok=True)\n", "\n", "# Save encoder for later use\n", "import pickle\n", "with open('models/feature_encoder.pkl', 'wb') as f:\n", "    pickle.dump(encoder, f)\n", "\n", "print(\"Feature dimensions:\", encoder.feature_dims)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train-Test Split"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sort by timestamp and take most recent as test\n", "interactions_df = interactions_df.sort_values('timestamp')\n", "train_interactions = interactions_df.iloc[:-100]  # All but last 100\n", "test_interactions = interactions_df.iloc[-100:]   # Last 100\n", "\n", "print(f\"Train: {len(train_interactions)}, Test: {len(test_interactions)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Two-Tower Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create datasets\n", "train_dataset = InvestorDealDataset(\n", "    train_interactions, investor_df, deal_df, \n", "    deal_df['dealId'].values, negative_samples=4\n", ")\n", "val_dataset = InvestorDealDataset(\n", "    test_interactions, investor_df, deal_df,\n", "    deal_df['dealId'].values, negative_samples=4\n", ")\n", "\n", "# Create dataloaders\n", "train_loader = torch.utils.data.DataLoader(\n", "    train_dataset, batch_size=128, shuffle=True, \n", "    collate_fn=collate_fn, num_workers=4 if torch.cuda.is_available() else 0\n", ")\n", "val_loader = torch.utils.data.DataLoader(\n", "    val_dataset, batch_size=128, shuffle=False,\n", "    collate_fn=collate_fn, num_workers=4 if torch.cuda.is_available() else 0\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Initialize Two-Tower model\n", "two_tower_model = TwoTowerModel(\n", "    n_investors=len(investor_df),\n", "    n_deals=len(deal_df),\n", "    feature_dims=encoder.feature_dims\n", ")\n", "\n", "# Setup callbacks\n", "checkpoint_callback = ModelCheckpoint(\n", "    dirpath='models/checkpoints',\n", "    filename='two-tower-{epoch:02d}-{val_loss:.3f}',\n", "    save_top_k=1,\n", "    monitor='val_loss',\n", "    mode='min'\n", ")\n", "\n", "early_stop_callback = EarlyStopping(\n", "    monitor='val_loss',\n", "    patience=5,\n", "    mode='min'\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Two-Tower\n", "trainer = pl.Trainer(\n", "    max_epochs=20,\n", "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n", "    devices=1,\n", "    callbacks=[checkpoint_callback, early_stop_callback],\n", "    enable_progress_bar=True\n", ")\n", "\n", "trainer.fit(two_tower_model, train_loader, val_loader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plot Two-Tower Training Curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot training curves\n", "plt.figure(figsize=(10, 4))\n", "plt.plot(two_tower_model.train_losses, label='Train Loss')\n", "plt.plot(two_tower_model.val_losses, label='Val Loss')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('Loss')\n", "plt.title('Two-Tower Model Loss')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.savefig('models/two_tower_loss.png')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Deep Ranking Model with Pairwise Loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create pairwise datasets\n", "train_pairwise = PairwiseRankingDataset(\n", "    train_interactions, investor_df, deal_df,\n", "    n_pairs_per_positive=5\n", ")\n", "val_pairwise = PairwiseRankingDataset(\n", "    test_interactions, investor_df, deal_df,\n", "    n_pairs_per_positive=3\n", ")\n", "\n", "# Create dataloaders\n", "train_pairwise_loader = torch.utils.data.DataLoader(\n", "    train_pairwise, batch_size=128, shuffle=True,\n", "    collate_fn=pairwise_collate_fn, num_workers=4 if torch.cuda.is_available() else 0\n", ")\n", "val_pairwise_loader = torch.utils.data.DataLoader(\n", "    val_pairwise, batch_size=128, shuffle=False,\n", "    collate_fn=pairwise_collate_fn, num_workers=4 if torch.cuda.is_available() else 0\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Initialize Deep Ranking model\n", "deep_ranking_model = PairwiseDeepRankingModel(\n", "    n_investors=len(investor_df),\n", "    n_deals=len(deal_df),\n", "    feature_dims=encoder.feature_dims\n", ")\n", "\n", "# Setup callbacks\n", "dr_checkpoint_callback = ModelCheckpoint(\n", "    dirpath='models/checkpoints',\n", "    filename='deep-ranking-{epoch:02d}-{val_loss:.3f}',\n", "    save_top_k=1,\n", "    monitor='val_loss',\n", "    mode='min'\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Deep Ranking\n", "dr_trainer = pl.Trainer(\n", "    max_epochs=20,\n", "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n", "    devices=1,\n", "    callbacks=[dr_checkpoint_callback, early_stop_callback],\n", "    enable_progress_bar=True\n", ")\n", "\n", "dr_trainer.fit(deep_ranking_model, train_pairwise_loader, val_pairwise_loader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save Training Summary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["summary = {\n", "    'two_tower_best_ckpt': checkpoint_callback.best_model_path,\n", "    'deep_ranking_best_ckpt': dr_checkpoint_callback.best_model_path,\n", "    'n_investors': len(investor_df),\n", "    'n_deals': len(deal_df),\n", "    'feature_dims': encoder.feature_dims\n", "}\n", "\n", "import json\n", "with open('models/training_summary.json', 'w') as f:\n", "    json.dump(summary, f, indent=2)\n", "\n", "print(\"Training completed!\")\n", "print(f\"Two-Tower best checkpoint: {summary['two_tower_best_ckpt']}\")\n", "print(f\"Deep Ranking best checkpoint: {summary['deep_ranking_best_ckpt']}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 4}
